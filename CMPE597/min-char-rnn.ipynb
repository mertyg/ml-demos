{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MERT YUKSEKGONUL\n",
    "### 2016402147"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NTtOiRzYixSp"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YfpGY2GF9JtS"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jNW3cQLwRURz"
   },
   "source": [
    "I have trained the model on Donald Trump's speeches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1y4T1fSSivtr"
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "  # Subtract max for stabilization, preventing overflow etc.  \n",
    "  x_s = x-np.max(x)\n",
    "  return np.exp(x_s) / np.sum(np.exp(x_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7B1p9vuMv59q"
   },
   "outputs": [],
   "source": [
    "# I will use the single layered vanilla char-rnn model, with adam optimizer.\n",
    "\n",
    "class CharRNN:\n",
    "  def __init__(self, d_hidden, d_vocab, maps, seq_len = 25, w_init=0.01, learning_rate=0.01, beta1=0.9, beta2=0.999, epsilon=1e-08):\n",
    "    \"\"\"\n",
    "    Character predictor RNN model. Author: Mert Yuksekgonul (@mertyg)\n",
    "    d_hidden, d_vocab : Hidden size and vocab size, int\n",
    "    maps : A list of maps. First one is expected to be a char to index map, second one is the reverse index to char map.\n",
    "    seq_len : Length of windows to be considered\n",
    "    w_init : Initialization constant for weight matrices.\n",
    "    learning_rate : lr for adam.\n",
    "    beta1, beta2, epsilon: other parameters for adam optimization\n",
    "    \"\"\"\n",
    "    self.d_h = d_hidden\n",
    "    self.d_v = d_vocab\n",
    "    np.random.seed(0)\n",
    "    self.Whx = np.random.randn(d_hidden, d_vocab)*w_init\n",
    "    self.Whh = np.random.randn(d_hidden, d_hidden)*w_init\n",
    "    self.Wyh = np.random.randn(d_vocab, d_hidden)*w_init\n",
    "    self.bh = np.zeros((d_hidden, 1))\n",
    "    self.by = np.zeros((d_vocab, 1))\n",
    "    self.lr = learning_rate\n",
    "    self.beta1 = beta1\n",
    "    self.beta2 = beta2\n",
    "    self.epsilon = epsilon\n",
    "    self.char_ix = maps[0]\n",
    "    self.ix_char = maps[1]\n",
    "    self.seq_len = 25\n",
    "    self.mWyh, self.vWyh = np.zeros_like(self.Wyh), np.zeros_like(self.Wyh)\n",
    "    self.mWhx, self.vWhx = np.zeros_like(self.Whx), np.zeros_like(self.Whx)\n",
    "    self.mWhh, self.vWhh = np.zeros_like(self.Whh), np.zeros_like(self.Whh)\n",
    "    self.mby, self.vby = np.zeros_like(self.by), np.zeros_like(self.by)\n",
    "    self.mbh, self.vbh = np.zeros_like(self.bh), np.zeros_like(self.bh)\n",
    "  \n",
    "  def _forward_cell(self, h_prev, x):\n",
    "    h_next = np.tanh(np.dot(self.Whh, h_prev) + np.dot(self.Whx, x) + self.bh)\n",
    "    pred = softmax(np.dot(self.Wyh, h_next) + self.by)\n",
    "    return h_next, pred\n",
    "  \n",
    "  def _forward_pass(self, inputs, h):\n",
    "    #h = np.zeros((self.d_h, 1))\n",
    "    hiddens = {}\n",
    "    hiddens[-1] = h\n",
    "    preds = {}\n",
    "    for i in range(len(inputs)):\n",
    "      x_t = inputs[i]\n",
    "      h, pred = self._forward_cell(hiddens[i-1], x_t)\n",
    "      hiddens[i] = h\n",
    "      preds[i] = pred\n",
    "    return hiddens, preds\n",
    "  \n",
    "  \n",
    "  def _backward_cell(self, dh_next, h_prev, h, x_t, p_t, t):\n",
    "    dy = np.copy(p_t)\n",
    "    dy[t] -= 1\n",
    "    dWyh = np.dot(dy, h.T)\n",
    "    dby = dy\n",
    "    dh = np.dot(self.Wyh.T, dy) + dh_next\n",
    "    dtanh = (1 - h ** 2) * dh\n",
    "    dbh = dtanh\n",
    "    dWhx = np.dot(dtanh, x_t.T)\n",
    "    dh_prev = np.dot(self.Whh.T, dtanh)\n",
    "    dWhh = np.dot(dtanh, h_prev.T)\n",
    "    return dh_prev, dWyh, dWhx, dWhh, dby, dbh\n",
    "    \n",
    "  def _backward_pass(self, hiddens, preds, inputs, targets):\n",
    "    dWhx, dWhh, dWyh = np.zeros_like(self.Whx), np.zeros_like(self.Whh), np.zeros_like(self.Wyh)\n",
    "    dbh, dby = np.zeros_like(self.bh), np.zeros_like(self.by)\n",
    "    dh_next = np.zeros_like(hiddens[0])\n",
    "    for i in reversed(range(len(targets))):\n",
    "      grads = self._backward_cell(dh_next, hiddens[i-1], hiddens[i], inputs[i], preds[i], targets[i])\n",
    "      dh_next = grads[0]\n",
    "      dWyh += grads[1]\n",
    "      dWhx += grads[2]\n",
    "      dWhh += grads[3]\n",
    "      dby += grads[4]\n",
    "      dbh += grads[5]\n",
    "    grads = [dWyh, dWhx, dWhh, dby, dbh]\n",
    "    for param in grads:\n",
    "      np.clip(param, -5, 5, out=param)\n",
    "    return grads\n",
    "    \n",
    "    \n",
    "  def _evaluate(self,inputs, targets, prev_h):\n",
    "    hiddens, preds = self._forward_pass(inputs, prev_h)\n",
    "    loss = 0\n",
    "    for t in range(len(targets)):\n",
    "      loss += -np.log(preds[t][targets[t], 0])\n",
    "    grads = self._backward_pass(hiddens, preds, inputs, targets)\n",
    "      \n",
    "    return loss, hiddens[len(targets)-1], grads\n",
    "  \n",
    "  \n",
    "  def train(self, input_txt):        \n",
    "    t = 0\n",
    "    window = 0\n",
    "    total_loss = 0.\n",
    "    batches = 1\n",
    "    prev_h = np.zeros((hidden_size, 1)) \n",
    "    loss_hist = []\n",
    "    \n",
    "    \n",
    "    while True:      \n",
    "      if batches % 10000 == 0:\n",
    "        print(\"Mean loss so far: \", total_loss/batches)\n",
    "        #if len(loss_hist) > 10 and total_loss/batches > 0.999*loss_hist[-1] and loss_hist[-1] > 0.999*loss_hist[-2] and loss_hist[-2] > 0.999*loss_hist[-3]:\n",
    "        #  break\n",
    "        loss_hist.append(total_loss/batches)\n",
    "        total_loss = 0\n",
    "        batches = 0\n",
    "      \n",
    "      if window+self.seq_len+1 >= len(input_txt):\n",
    "        window = 0\n",
    "        prev_h = np.zeros((hidden_size, 1))\n",
    "        \n",
    "      data = [self.char_ix[ch] for ch in input_txt[window : window + self.seq_len]]\n",
    "      inputs = {}\n",
    "      for t in range(len(data)):\n",
    "        inputs[t] = np.zeros((self.d_v, 1))\n",
    "        inputs[t][data[t]] = 1\n",
    "        \n",
    "      targets = [self.char_ix[ch] for ch in input_txt[window + 1 : window + self.seq_len + 1]]\n",
    "      \n",
    "      \n",
    "      loss, prev_h, grads = self._evaluate(inputs, targets, prev_h)\n",
    "      window += self.seq_len\n",
    "      total_loss += loss\n",
    "      batches += 1\n",
    "      \n",
    "      for param, g, m, v in zip([self.Wyh, self.Whx, self.Whh, self.by, self.bh],\n",
    "                                grads,\n",
    "                                [self.mWyh, self.mWhx, self.mWhh, self.mby, self.mbh],\n",
    "                                [self.vWyh, self.vWhx, self.vWhh, self.vby, self.vbh]):\n",
    "        t+=1\n",
    "        m_prev = m\n",
    "        v_prev = v\n",
    "        m += self.beta1 * m_prev + (1 - self.beta1) * g - m_prev\n",
    "        v += self.beta2 * v_prev + (1 - self.beta2) * np.power(g, 2) - v_prev\n",
    "        m_hat = m / (1 - np.power(self.beta1, t)) + (1 - self.beta1) * g / (1 - np.power(self.beta1, t))\n",
    "        v_hat = v / (1 - np.power(self.beta2, t))\n",
    "        param -= self.lr * m_hat / (np.sqrt(v_hat) + self.epsilon)\n",
    "    \n",
    "    print(\"Training Complete!\")\n",
    "    \n",
    "    \n",
    "  def generate(self, sample, sample_size):\n",
    "    sample_input = {}\n",
    "    for i in range(len(sample)-1):\n",
    "      data = np.zeros((self.d_v, 1))\n",
    "      data[self.char_ix[sample[i]]] = 1\n",
    "      sample_input[i] = data\n",
    "    h_prev = np.zeros((self.d_h, 1))\n",
    "    hiddens, preds = self._forward_pass(sample_input, h_prev)\n",
    "    h_prev = hiddens[len(sample_input)-1]\n",
    "  \n",
    "    x_ix = [self.char_ix[ch] for ch in sample[-1]]\n",
    "    x = np.zeros((self.d_v, 1))\n",
    "    x[self.char_ix[sample[-1]]] = 1\n",
    "    sampled = []\n",
    "    \n",
    "    for i in range(sample_size):\n",
    "      h_prev, pred = self._forward_cell(h_prev, x)\n",
    "      pos = np.random.choice(range(self.d_v), p=pred.ravel())\n",
    "      x = np.zeros((self.d_v, 1))\n",
    "      x[pos] = 1\n",
    "      sampled.append(self.ix_char[pos])\n",
    "    \n",
    "    sample_txt = \"\".join(sampled)\n",
    "    print(sample, sample_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q47aMuv7lAnu"
   },
   "outputs": [],
   "source": [
    "data = open('./trial/speeches.txt', 'r').read()\n",
    "chars = list(set(data))\n",
    "vocab_size = len(chars)\n",
    "hidden_size = 200\n",
    "charmap = { ch:i for i,ch in enumerate(chars) }\n",
    "ixmap = { i:ch for i,ch in enumerate(chars) }\n",
    "model = CharRNN(hidden_size, vocab_size, [charmap, ixmap], learning_rate=0.001, seq_len=seq_length)\n",
    "history = model.train(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "colab_type": "code",
    "id": "unczuXWQju5F",
    "outputId": "fcfc9c4a-9975-40a0-9450-736229ec216a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "America . You can’t wait paying to killeh if you can be ablanduy. I think Geved that ban. Hillary trying groral credy – I back free seem now speakise in Tom for a vamberractare issued? You know to do sore and it guy two moner. O\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "These are the Debate, foruse – some people who do this anywhere it come, doan, way rego. Prowes ups contrnor. I was doing out by sought this doesn’t have to do? I took for a raving him byin \"I think way a young from our doll.\" I said they trilling down is tor your manut thing. And we have not see for mbailed to do the many, many of it. Can Brad worata. It’s sitticks that Hircaistce for a long time both solen. I say the people – he last thing to do so everythical.\n",
      "Clinated it lastens. They said, \"But you want to hambe the history and maybe these competently. We’re going to rume how states. We did. But she said \"What a ro do, womon.\n",
      "\" for 41% and when do semendless wigh carrina, we swer. I said, \"What have to bone.\n",
      "So this told Trumparatice.\" I’ll the enstwaria.\n",
      "I love Hurritely bad rutting bankmonk? They don’t go to talk it was beonal thousands, work for Trump says right. But she agration.\n",
      "And we’re going to come in livere was going to cook to anybody and maying about throff one, what drea.\n",
      "95 yances? A should a back.\n",
      "And I’s doing the veterans disairates? So he Rupectinustileney to Pruz. It they don’t know what the words busised to 91%, I think they’re earled Toop.\n",
      "Because, so you in do bracts to five much poseres and the should last trea soot sort of num\n"
     ]
    }
   ],
   "source": [
    "model.generate(\"America\", sample_size = 1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7qgXKLMp_NTL",
    "outputId": "94e13343-5ad9-440f-8087-328a2cc15ef3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your  agoundster a president.\n",
      "You know the veterankly, angry it. Well, I have to do the common From. We’re great pulitically 45 mangef long in him just military – you know, like some of the end our raidg.\n",
      "I know the kind your was much annories powed in New Hameshing anyther to come in was Bublina, I heard about it as they do. I would beson gent, certements to gever for so taking like them. I think it’s the esticiale. But we talk about anything it with 5% an said, \"Well, of the bolly was success. They don’t lore I don’t know any montinepsest in threartes, wisnor than unementth.\n",
      "And that’s to making killing to be yourreds of doesn’t suck the Bunzy wrong in. And they didn’t be for a long time, to just walk.\n",
      "So, you atrong it.\n",
      "And thinks about many of coupped forget is very excailly any big laterults. And acroughter.\n",
      "There’s some of to funcriviculfralicals – anstee trate debate. But it down. And soec Catcord out in Fox. So many. You know who’s profors that When Israel doestieve we have to wast to give it but I would sted fibs freen ham put and I so do chinable americh.\n",
      "So we get a fron. I wrialade – any goodent thing sure because I think bohing 200y job, no book, we know low of thes hig. For your over, now it’s more difed. Actually know who wast. Because – he said \"How do you fabe that it sookiolies Trade day divorners.\n",
      "\n",
      "\n",
      "I guess onaring working by the I’ve nevel sum a plise that I’m going to do they whething frees of contina? Remember. It’s the shows.\n",
      "But when you know I was vore wit\n"
     ]
    }
   ],
   "source": [
    "model.generate(\"Your\", sample_size = 1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rx9GXzAwQsUt",
    "outputId": "36d38f67-56d1-427f-8125-81b3c9f931fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go us become out sole out right?\n",
      "But they have no from Muss advinities.\n",
      "But I wasth? You’re sord or treates for this and rape turn’t happen. I love.\n",
      "So they didn’t see the same approved a yeat?\" It that stries to stop said Are in Iowa?\" And then we have to expelsed and just wasn’t have to use that could bean in the other thinkwork – I took who it were sort of money to or build. Will mess it would have see hupe in bad? I said \"These in Scumings to I was think it’s the Bingunes on heatinest better good jobs. I love Trump. I heper and everybody.\n",
      "Now, alowere buildicelably rediticals our scement.\n",
      "You know, the other dived, the Deal Hillary in only been was gine and to do. And I scates. They using Aur. Plints this day\" Some of the White Horved in the Alankloy.\n",
      "Mark our counsing your loppanics. When I soot.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The stopa like. But I say they looking mouth was gaiting History at the cozrane.\n",
      "My your dourast to the America Iobalie than stregite, and then you know Mexico. When Ickionips you reel – a vero hard to do whill so Naptricted fuy they no with whates to call it. We’re doing so special.\n",
      "And $200,000 big the finh – money our cape and his I have under work in the money suaned time it so tremendoust.\n",
      " Tobde goad including bad amount.\" They believe me, these cits. The world times. You know the hotel Sandies\". It’s this doengs.\n",
      "So Doray: So, so we or a suge antifully he’s great. And I undenstoness – the Wall – he’s going to chat happening. And we have a supposed in While and hit do o\n"
     ]
    }
   ],
   "source": [
    "model.generate(\"Go\", sample_size = 1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "30Qi43YvQsUv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HW2-2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
